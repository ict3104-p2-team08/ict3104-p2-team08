{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ict3104-p2-team08/ict3104-p2-team08/blob/inference_feat/3104_T08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJLCy-Wv_Rd"
      },
      "source": [
        "# Activity Detection ML Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyKsO3crw1K5"
      },
      "source": [
        "## 1. Prerequisites\n",
        "\n",
        "This section provides the setting up of the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "heoGQJ7NyBiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fa6fd7-2874-4e82-9914-1d335a7735cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchaudio) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torchsummary==1.5.1 in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: torchtext==0.13.1 in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.1) (4.64.1)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchtext==0.13.1) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.1) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch -f https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install torchaudio -f https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install torchsummary==1.5.1 torchtext==0.13.1 torchvision -f https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KapnAnp1HjCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e421bec-ced0-4884-8fcb-54035e2b3c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'video_features'...\n",
            "remote: Enumerating objects: 1283, done.\u001b[K\n",
            "remote: Counting objects: 100% (381/381), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 1283 (delta 245), reused 295 (delta 200), pack-reused 902\u001b[K\n",
            "Receiving objects: 100% (1283/1283), 288.54 MiB | 28.89 MiB/s, done.\n",
            "Resolving deltas: 100% (664/664), done.\n",
            "Checking out files: 100% (177/177), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting omegaconf==2.0.6\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.6) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.6) (4.1.1)\n",
            "Installing collected packages: omegaconf\n",
            "Successfully installed omegaconf-2.0.6\n",
            "Cloning into 'ict3104-p2-team08'...\n",
            "remote: Enumerating objects: 707, done.\u001b[K\n",
            "remote: Counting objects: 100% (389/389), done.\u001b[K\n",
            "remote: Compressing objects: 100% (385/385), done.\u001b[K\n",
            "remote: Total 707 (delta 5), reused 378 (delta 4), pack-reused 318\u001b[K\n",
            "Receiving objects: 100% (707/707), 3.75 GiB | 28.27 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Checking out files: 100% (607/607), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/v-iashin/video_features.git\n",
        "!pip install omegaconf==2.0.6\n",
        "!git clone --branch inference_feat https://github.com/ict3104-p2-team08/ict3104-p2-team08.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQXemWrcw4pE"
      },
      "outputs": [],
      "source": [
        "# Imports widgets for jupyter\n",
        "try:\n",
        "    import piplite\n",
        "    piplite.install(['ipywidgets'])\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcEvKDf2wVL2"
      },
      "source": [
        "## 2. Toggling of pipelines\n",
        "\n",
        "This section shows the toggling of dependencies between TSU and STEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb4Grr9wuhWu"
      },
      "outputs": [],
      "source": [
        "#insert code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voFOEyiP0WSt"
      },
      "source": [
        "## 3. Data exploration\n",
        "\n",
        "This section load and display video data from the Toyota Smarthome (TSU) project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnSmkBhh0KkY"
      },
      "outputs": [],
      "source": [
        "#import tsu video files\n",
        "import os\n",
        "FOLDER_PATH = 'input_files'\n",
        "ROOT_PATH = '/content/data'\n",
        "\n",
        "file_list = os.listdir(os.path.join(ROOT_PATH, FOLDER_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dgd963k-3DR"
      },
      "outputs": [],
      "source": [
        "#tsu video files to display in dropdown\n",
        "from ipywidgets import  Dropdown, widgets\n",
        "\n",
        "w = widgets.Dropdown(\n",
        "    options= file_list,\n",
        ")\n",
        "\n",
        "def on_change(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        print(change['new'])\n",
        "\n",
        "w.observe(on_change)\n",
        "\n",
        "display(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB0moBiBCpVL"
      },
      "outputs": [],
      "source": [
        "#display video \n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "video_path = '/content/data/input_files/%' + w.value\n",
        "\n",
        "locate= \"\" \n",
        "\n",
        "for i in video_path: \n",
        "   if i=='%': \n",
        "       pass\n",
        "   else: \n",
        "       locate+=i \n",
        "\n",
        "def show_video(locate, video_width = 500):\n",
        "  video_file = open(locate, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        "  \n",
        "show_video(locate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJJbEEdHNcJU"
      },
      "outputs": [],
      "source": [
        "#only run it for the first time\n",
        "%cd video_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2kz9WWwFbY6"
      },
      "outputs": [],
      "source": [
        "#extract to I3D feature file\n",
        "from models.i3d.extract_i3d import ExtractI3D\n",
        "from utils.utils import build_cfg_path\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "\n",
        "# Select the feature type\n",
        "feature_type = 'i3d'\n",
        "args = OmegaConf.load(build_cfg_path(feature_type))\n",
        "args.video_paths = ['/content/data/input_files/P02T02C06.mp4']\n",
        "args.flow_type = 'raft'\n",
        "\n",
        "extractor = ExtractI3D(args)\n",
        "print(locate)\n",
        "\n",
        "# Extract features\n",
        "for video_path in args.video_paths:\n",
        "    print(f'Extracting for {video_path}')\n",
        "    feature_dict = extractor.extract(video_path)\n",
        "    [(print(k), print(v.shape), print(v)) for k, v in feature_dict.items()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pbFLqFs08xy"
      },
      "source": [
        "## 4. Inference with pretrained model\n",
        "\n",
        "This section shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4D84kQqh0-1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17fda50-ff6b-4f13-c13f-ad5dcb9a5118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random_SEED!!!: 0\n",
            "PDAN\n",
            "batch_size: 2\n",
            "cuda_avail False\n",
            "RGB mode ./ict3104-p2-team08/Toyota_Smarthome/pipline/data/RGB_i3d_16frames_64000_SSD\n",
            "100% 536/536 [00:07<00:00, 71.91it/s] \n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 536/536 [00:04<00:00, 125.91it/s]\n",
            "you are processing PDAN\n",
            "/content/ict3104-p2-team08/Toyota_Smarthome/pipline/models.py:88: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  init.kaiming_normal(self.key_conv.weight, mode='fan_out')\n",
            "/content/ict3104-p2-team08/Toyota_Smarthome/pipline/models.py:89: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  init.kaiming_normal(self.value_conv.weight, mode='fan_out')\n",
            "/content/ict3104-p2-team08/Toyota_Smarthome/pipline/models.py:90: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  init.kaiming_normal(self.query_conv.weight, mode='fan_out')\n",
            "/content/ict3104-p2-team08/Toyota_Smarthome/pipline/models.py:91: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  init.normal(self.rel_t, 0, 1)\n",
            "Traceback (most recent call last):\n",
            "  File \"./ict3104-p2-team08/Toyota_Smarthome/pipline/test2.py\", line 425, in <module>\n",
            "    model = torch.load(args.load_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 712, in load\n",
            "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 1049, in _load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 1019, in persistent_load\n",
            "    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 1001, in load_tensor\n",
            "    wrap_storage=restore_location(storage, location),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 175, in default_restore_location\n",
            "    result = fn(storage, location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 152, in _cuda_deserialize\n",
            "    device = validate_cuda_device(location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 136, in validate_cuda_device\n",
            "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
            "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
          ]
        }
      ],
      "source": [
        "#insert codes here\n",
        "!python ./ict3104-p2-team08/Toyota_Smarthome/pipline/test2.py -videofile=P18T15C03 -model=PDAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5cqhsmO1TW5"
      },
      "source": [
        "## 5. Testing and evaluating trained models\n",
        "\n",
        "This section shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KUHMF5Pr1XjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "1f5edc5d-708c-4ada-e36d-83c19dbc1e0b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-08b7788065c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#insert codes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "#insert codes here\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyUzIqvd3rue"
      },
      "source": [
        "## 6. Training of new model\n",
        "\n",
        "This section shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ3NT9Et3wnT"
      },
      "outputs": [],
      "source": [
        "#insert codes here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4pbFLqFs08xy"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}