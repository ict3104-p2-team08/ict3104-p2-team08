{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ict3104-p2-team08/ict3104-p2-team08/blob/inference_feat/3104_T08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJLCy-Wv_Rd"
      },
      "source": [
        "# Activity Detection ML Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyKsO3crw1K5"
      },
      "source": [
        "## 1. Prerequisites\n",
        "\n",
        "This section provides the setting up of the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heoGQJ7NyBiM"
      },
      "outputs": [],
      "source": [
        "!pip install torch -f https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install torchaudio -f https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install torchsummary==1.5.1 torchtext==0.13.1 torchvision -f https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KapnAnp1HjCk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/v-iashin/video_features.git\n",
        "!pip install omegaconf==2.0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQXemWrcw4pE"
      },
      "outputs": [],
      "source": [
        "# Imports widgets for jupyter\n",
        "try:\n",
        "    import piplite\n",
        "    piplite.install(['ipywidgets'])\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcEvKDf2wVL2"
      },
      "source": [
        "## 2. Toggling of pipelines\n",
        "\n",
        "This section shows the toggling of dependencies between TSU and STEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb4Grr9wuhWu"
      },
      "outputs": [],
      "source": [
        "#insert code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voFOEyiP0WSt"
      },
      "source": [
        "## 3. Data exploration\n",
        "\n",
        "This section load and display video data from the Toyota Smarthome (TSU) project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnSmkBhh0KkY"
      },
      "outputs": [],
      "source": [
        "#import tsu video files\n",
        "import os\n",
        "FOLDER_PATH = 'input_files'\n",
        "ROOT_PATH = '/content/data'\n",
        "\n",
        "file_list = os.listdir(os.path.join(ROOT_PATH, FOLDER_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dgd963k-3DR"
      },
      "outputs": [],
      "source": [
        "#tsu video files to display in dropdown\n",
        "from ipywidgets import  Dropdown, widgets\n",
        "\n",
        "w = widgets.Dropdown(\n",
        "    options= file_list,\n",
        ")\n",
        "\n",
        "def on_change(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        print(change['new'])\n",
        "\n",
        "w.observe(on_change)\n",
        "\n",
        "display(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB0moBiBCpVL"
      },
      "outputs": [],
      "source": [
        "#display video \n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "video_path = '/content/data/input_files/%' + w.value\n",
        "\n",
        "locate= \"\" \n",
        "\n",
        "for i in video_path: \n",
        "   if i=='%': \n",
        "       pass\n",
        "   else: \n",
        "       locate+=i \n",
        "\n",
        "def show_video(locate, video_width = 500):\n",
        "  video_file = open(locate, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        "  \n",
        "show_video(locate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJJbEEdHNcJU"
      },
      "outputs": [],
      "source": [
        "#only run it for the first time\n",
        "%cd video_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2kz9WWwFbY6"
      },
      "outputs": [],
      "source": [
        "#extract to I3D feature file\n",
        "from models.i3d.extract_i3d import ExtractI3D\n",
        "from utils.utils import build_cfg_path\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "\n",
        "# Select the feature type\n",
        "feature_type = 'i3d'\n",
        "args = OmegaConf.load(build_cfg_path(feature_type))\n",
        "args.video_paths = ['/content/data/input_files/P02T02C06.mp4']\n",
        "args.flow_type = 'raft'\n",
        "\n",
        "extractor = ExtractI3D(args)\n",
        "print(locate)\n",
        "\n",
        "# Extract features\n",
        "for video_path in args.video_paths:\n",
        "    print(f'Extracting for {video_path}')\n",
        "    feature_dict = extractor.extract(video_path)\n",
        "    [(print(k), print(v.shape), print(v)) for k, v in feature_dict.items()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pbFLqFs08xy"
      },
      "source": [
        "## 4. Inference with pretrained model\n",
        "\n",
        "This section shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D84kQqh0-1_"
      },
      "outputs": [],
      "source": [
        "#insert codes here\n",
        "\n",
        "#test edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5cqhsmO1TW5"
      },
      "source": [
        "## 5. Testing and evaluating trained models\n",
        "\n",
        "This section shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUHMF5Pr1XjJ"
      },
      "outputs": [],
      "source": [
        "#insert codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyUzIqvd3rue"
      },
      "source": [
        "## 6. Training of new model\n",
        "\n",
        "This section shows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ3NT9Et3wnT"
      },
      "outputs": [],
      "source": [
        "#insert codes here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4pbFLqFs08xy"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}