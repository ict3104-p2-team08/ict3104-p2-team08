{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ict3104-p2-team08/ict3104-p2-team08/blob/inference_feat/3104_T08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yJLCy-Wv_Rd"
   },
   "source": [
    "# Activity Detection ML Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyKsO3crw1K5"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This section provides the setting up of the environment and dependencies required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heoGQJ7NyBiM",
    "outputId": "a2fa6fd7-2874-4e82-9914-1d335a7735cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch -f https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install torchaudio -f https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install torchsummary==1.5.1 torchtext==0.13.1 torchvision -f https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FQXemWrcw4pE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown, widgets\n",
    "import os\n",
    "from IPython.display import HTML, Video, clear_output\n",
    "from base64 import b64encode\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter wandb api key and username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_key = widgets.Text(description='Api key:')\n",
    "display(wandb_key)\n",
    "wandb_username = widgets.Text(description='Username:')\n",
    "display(wandb_username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login {wandb_key.value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### TSU (RGB variant only)\n",
    "\n",
    "#### Importing TSU provided Video/CSV files.\n",
    "\n",
    "##### For video files\n",
    "Step 1. Go to /ict3104-p2-team08/data/input_files/ directory\n",
    "<br>\n",
    "Step 2. Add in video files provided by TSU (Feature extraction/inference needed)\n",
    "##### For CSV files\n",
    "Step 1. Go to /ict3104-p2-team08/data/input_csv/ directory\n",
    "<br>\n",
    "Step 2. Add in CSV files provided by TSU (Inference needed to show actual annotated result)\n",
    "\n",
    "#### Importing TSU provided NPY files.\n",
    "Step 1. Go to /Toyota_Smarthome/pipline/data/RGB_i3d_16frames_64000_SSD/ directory\n",
    "<br>\n",
    "Step 2. Add in all npy files provided by TSU\n",
    "\n",
    "#### Importing V-iashin provided RGB NPY files.\n",
    "If you have already extracted the RGB NPY files do the following:\n",
    "<br>\n",
    "Step 1. Go to /ict3104-p2-team08/Toyota_Smarthome/pipline/data/RGB_v_iashin/ directory\n",
    "<br>\n",
    "Step 2. Add in the v-iashin extracted rgb npy files\n",
    "<br>\n",
    "If not extracted can make use of feature extraction section below (Note: feature extraction is only possible for TSU videos that can be found in <br> /ict3104-p2-team08/data/input_files/ directory)\n",
    "\n",
    "#### Importing TSU provided Pretrained model (PDAN).\n",
    "Step 1. Go to /ict3104-p2-team08/Toyota_Smarthome/pipline/models/ directory\n",
    "<br>\n",
    "Step 2. Add in PDAN provided by TSU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### STEP\n",
    "\n",
    "#### Importing STEP provided Video files.\n",
    "\n",
    "##### For video files\n",
    "##### Training video files\n",
    "Step 1. Go to /ict3104-p2-team08/STEP/datasets/ava/videos/train_vid/ directory\n",
    "<br>\n",
    "Step 2. Add in training video files provided by AVA\n",
    "##### Testing video files\n",
    "Step 1. Go to /ict3104-p2-team08/STEP/datasets/ava/videos/val_vid/ directory\n",
    "<br>\n",
    "Step 2. Add in validation video files provided by AVA\n",
    "\n",
    "#### Importing STEP provided Pretrained model (ava_step.pth).\n",
    "Step 1. Go to /ict3104-p2-team08/STEP/pretrained/ directory\n",
    "<br>\n",
    "Step 2. Add in ava_step.pth provided by AVA\n",
    "\n",
    "#### To extract video frames for newly added videos (for training/testing) in /ict3104-p2-team08/STEP/datasets/ava/videos/ directory, run the below cell (Note: Run section 2 Toggling of pipelines and check STEP radio button first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -i ./scripts/extract_clips.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcEvKDf2wVL2"
   },
   "source": [
    "## Toggling of pipelines\n",
    "\n",
    "This section shows the toggling of dependencies between TSU and STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lb4Grr9wuhWu",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4691987938485d9c065a0865120c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Pipelines:', options=('TSU', 'STEP', 'MSTCT'), value='TSU')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current selected pipeline: STEP  \r"
     ]
    }
   ],
   "source": [
    "current_pipeline = \"TSU\"\n",
    "rb = widgets.RadioButtons(\n",
    "    options=['TSU', 'STEP', 'MSTCT'],\n",
    "    description='Pipelines:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    global current_pipeline\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        if current_pipeline != change['new']:\n",
    "            if change['new'] == \"TSU\":\n",
    "                %cd -q ../\n",
    "            elif change['new'] == \"STEP\":\n",
    "                if os.path.basename(os.path.normpath(os.getcwd())) ==\"MSTCT\":\n",
    "                    %cd -q ..\n",
    "                    %cd -q  ./STEP\n",
    "                else:\n",
    "                    %cd -q  ./STEP\n",
    "            elif change['new'] == \"MSTCT\":\n",
    "                if os.path.basename(os.path.normpath(os.getcwd())) ==\"STEP\":\n",
    "                    %cd -q ../\n",
    "                    %cd -q ./MSTCT\n",
    "                else:\n",
    "                    %cd -q ./MSTCT\n",
    "        current_pipeline = change['new']\n",
    "        print(\"Current selected pipeline: {:<6}\".format(current_pipeline), end='\\r')\n",
    "\n",
    "rb.observe(on_change)\n",
    "\n",
    "display(rb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voFOEyiP0WSt"
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "This section load and display video data from the Toyota Smarthome (TSU) project\n",
    "\n",
    "### Jupyter -- Upload any files/datasets into the main folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717333be24d54422be63532264ff170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.mp4', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = widgets.FileUpload(accept='.mp4',  multiple=True)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd Documents/GitHub/ict3104-p2-team08\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " video file does not belong to STEP\n"
     ]
    }
   ],
   "source": [
    "#test = uploader.value\n",
    "import pandas as pd\n",
    "\n",
    "#depends on pipeline\n",
    "\n",
    "def return_name():\n",
    "    for name, file_info in uploader.value.items():\n",
    "        name_file = name\n",
    "    return name_file\n",
    "    \n",
    "    \n",
    "def catch_err_before_begin():\n",
    "    uploader.value\n",
    "    if len(uploader.value) == 0:\n",
    "        print(\"An exception occurred\")\n",
    "        print(\"possible reason - file too large to upload. consider manual uploading of dataset in jupyter notebook\")\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def upload_to_path(dir):\n",
    "    try:\n",
    "        for name, file_info in uploader.value.items():\n",
    "            with open (name, 'wb') as file:\n",
    "                file.write(file_info['content'])\n",
    "        print(\"successful upload of\", name, \"to\", dir)\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "        \n",
    "        \n",
    "        \n",
    "# uplaod videos to data/input_files for tsu.\n",
    "# return back to root dir\n",
    "if current_pipeline == \"TSU\":\n",
    "    if catch_err_before_begin() == True:\n",
    "        %cd -q  ./data/input_files\n",
    "        upload_to_path(\"./data/input_files\")\n",
    "        %cd -q ../\n",
    "        %cd -q ../\n",
    "    \n",
    "\n",
    "# uplaod videos to data/input_files for mstct.\n",
    "# return back to mstct dir\n",
    "if current_pipeline == \"MSTCT\":\n",
    "    if catch_err_before_begin() == True:\n",
    "        %cd -q ../\n",
    "        %cd -q  ./data/input_files\n",
    "        upload_to_path(\"./data/input_files\")\n",
    "        %cd -q ../\n",
    "        %cd -q ../\n",
    "        %cd -q ./MSTCT\n",
    "    \n",
    "            \n",
    "if current_pipeline == \"STEP\":\n",
    "    #check if trainval or test\n",
    "    xl = pd.ExcelFile(\"./datasets/ava/check.xlsx\")\n",
    "    df = xl.parse(\"Sheet1\")\n",
    "    \n",
    "    if catch_err_before_begin() == True:\n",
    "        #name is not working\n",
    "        if return_name() in df.values:\n",
    "            print(name,\"exists in Dataframe\")\n",
    "            \n",
    "            row = df.loc[df['name'] == name]\n",
    "            get_type_trainval = row.loc[:,\"type\"] == \"trainval\"\n",
    "\n",
    "            #if video belongs to trainval\n",
    "            if get_type_trainval.bool() == True: \n",
    "                %cd -q  ./datasets/ava/videos/trainval\n",
    "                upload_to_path(\"./STEP/dataset/ava/videos/trainval\")\n",
    "            else:\n",
    "                %cd -q  ./datasets/ava/videos/test\n",
    "                upload_to_path(\"./STEP/dataset/ava/videos/test\")\n",
    "            %cd -q ../\n",
    "            %cd -q ../\n",
    "            %cd -q ../\n",
    "            %cd -q ../\n",
    "        else:\n",
    "            print(\" video file does not belong to STEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dgd963k-3DR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tsu video files to display in dropdown\n",
    "from ipywidgets import  Dropdown, widgets\n",
    "import os\n",
    "\n",
    "file_list = []\n",
    "if current_pipeline == \"TSU\":\n",
    "    FOLDER_PATH = 'input_files'\n",
    "    ROOT_PATH = './data'\n",
    "\n",
    "    file_list = os.listdir(os.path.join(ROOT_PATH, FOLDER_PATH))\n",
    "elif current_pipeline == \"STEP\":\n",
    "    for root, dirs, files in os.walk(\"./datasets/ava/videos\"):\n",
    "        for file in files:\n",
    "            #append the file name to the list\n",
    "            file_list.append(file)\n",
    "            \n",
    "elif current_pipeline == \"MSTCT\":\n",
    "    #change to whatever is needed\n",
    "    ROOT_PATH = './dataset'\n",
    "    file_list = os.listdir(os.path.join(ROOT_PATH))\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options= file_list,\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "\n",
    "w.observe(on_change)\n",
    "\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jB0moBiBCpVL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if current_pipeline == \"TSU\":\n",
    "    video_path = './data/input_files/%' + w.value\n",
    "elif current_pipeline == \"STEP\":\n",
    "    if os.path.isfile('./datasets/ava/videos/train_vid/' + w.value):\n",
    "        video_path = './datasets/ava/videos/train_vid/' + w.value\n",
    "    elif os.path.isfile('./datasets/ava/videos/val_vid/' + w.value):\n",
    "        video_path = './datasets/ava/videos/val_vid/' + w.value\n",
    "\n",
    "locate= \"\"\n",
    "\n",
    "for i in video_path: \n",
    "    if i=='%':\n",
    "        pass\n",
    "    else:\n",
    "        locate+=i \n",
    "\n",
    "def show_video(locate, video_width = 500):\n",
    "    video_file = open(locate, \"r+b\").read()\n",
    "    video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "    return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
    "  \n",
    "#Video(locate, embed=True, width=320, height=320)\n",
    "show_video(locate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction(TSU)\n",
    "\n",
    "This section allows extracting of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction prequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate training and testing lists base on cs json file\n",
    "def unextracted_list():\n",
    "    full_vid_list = \"./Toyota_Smarthome/pipline/data/smarthome_CS_51.json\"\n",
    "    full_vid_file = open(full_vid_list)\n",
    "    full_vid_json = json.load(full_vid_file)\n",
    "    \n",
    "    unextracted_vid_list = []\n",
    "    for vid_key in full_vid_json:\n",
    "        unextracted_vid_list.append(vid_key)\n",
    "        \n",
    "    extracted_vid_list = \"./Toyota_Smarthome/pipline/data/i3d_CS.json\"\n",
    "    extracted_vid_file = open(extracted_vid_list)\n",
    "    extracted_vid_json = json.load(extracted_vid_file)\n",
    "    \n",
    "    for extracted_vid_key in extracted_vid_json:\n",
    "        if extracted_vid_key[:-4] in unextracted_vid_list:\n",
    "            unextracted_vid_list.remove(extracted_vid_key[:-4])\n",
    "    unextracted_vid_list.sort()\n",
    "    return unextracted_vid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select video to extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unextracted_vid_sel = widgets.SelectMultiple(\n",
    "options=unextracted_list(),\n",
    "rows=10,\n",
    "description='Videos:',\n",
    "disabled=False\n",
    ")\n",
    "\n",
    "display(unextracted_vid_sel)\n",
    "\n",
    "selected_videos = []\n",
    "\n",
    "extract_but = widgets.Button(description = 'Extract')\n",
    "def on_ext_button_clicked(b):\n",
    "    combine_dataset = unextracted_vid_sel.value\n",
    "    selected_videos = list(combine_dataset)\n",
    "    selected_videos_string=(','.join(selected_videos))\n",
    "    #extract features as npy\n",
    "    %cd -q video_features\n",
    "    %pwd\n",
    "    %run -i ./test.py -videosToExtract={selected_videos_string}\n",
    "    %cd -q ..\n",
    "\n",
    "\n",
    "extract_but.on_click(on_ext_button_clicked)\n",
    "\n",
    "display(extract_but)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pbFLqFs08xy"
   },
   "source": [
    "## Inference with pretrained model\n",
    "\n",
    "This section allows generation of caption videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if current_pipeline == \"TSU\":\n",
    "    MODEL_PATH = 'models'\n",
    "    MODEL_ROOT_PATH = './Toyota_Smarthome/pipline/'\n",
    "\n",
    "    file_list = os.listdir(os.path.join(MODEL_ROOT_PATH, MODEL_PATH))\n",
    "elif current_pipeline == \"STEP\":\n",
    "    MODEL_PATH = ''\n",
    "    MODEL_ROOT_PATH = './pretrained'\n",
    "\n",
    "    file_list = os.listdir(os.path.join(MODEL_ROOT_PATH, MODEL_PATH))\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=file_list,\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "\n",
    "model_dropdown.observe(on_change)\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VIDEO_PATH = 'input_files'\n",
    "\n",
    "model_name = model_dropdown.value\n",
    "    \n",
    "#JSON_FILEPATH = \"./Toyota_Smarthome/pipline/model_videos.json\"\n",
    "#f = open(JSON_FILEPATH)\n",
    "#data = json.load(f)\n",
    "#testable_video = data[model_name]\n",
    "#testable_video = [video + \".mp4\" for video in testable_video]\n",
    "#print(testable_video)\n",
    "\n",
    "if current_pipeline == \"TSU\":\n",
    "    VIDEO_ROOT_PATH = './data/'\n",
    "    full_testable_video = os.listdir(os.path.join(VIDEO_ROOT_PATH, VIDEO_PATH))\n",
    "    \n",
    "    if model_name == \"PDAN\":\n",
    "        file_list = full_testable_video\n",
    "    else:\n",
    "        JSON_FILEPATH = \"./Toyota_Smarthome/pipline/data/\" + model_name + \"_CS.json\"\n",
    "        f = open(JSON_FILEPATH)\n",
    "        data = json.load(f)\n",
    "        testable_video = []\n",
    "        for video_key, video_values in data.items():\n",
    "            if video_values[\"subset\"] == \"testing\":\n",
    "                testable_video.append(video_key)\n",
    "        file_list = testable_video\n",
    "elif current_pipeline == \"STEP\":\n",
    "    full_testable_video = os.listdir(os.path.join('../data/', VIDEO_PATH))\n",
    "    file_list = full_testable_video\n",
    "\n",
    "video_dropdown = widgets.Dropdown(\n",
    "    options=file_list,\n",
    "    description='Video:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "\n",
    "video_dropdown.observe(on_change)\n",
    "display(video_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4D84kQqh0-1_",
    "outputId": "a17fda50-ff6b-4f13-c13f-ad5dcb9a5118",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if current_pipeline == \"TSU\":\n",
    "    video_selected = video_dropdown.value.replace('.mp4','')\n",
    "    model_selected = model_dropdown.value\n",
    "    model_path = \"./Toyota_Smarthome/pipline/models/\" + model_selected\n",
    "    %run -i ./Toyota_Smarthome/pipline/test2.py -videofile={video_selected} -load_model={model_path} -name={model_selected}\n",
    "    video_path = \"./Toyota_Smarthome/pipline/video_output/\" + video_selected + \"_caption.mp4\"\n",
    "elif current_pipeline == \"STEP\":\n",
    "    %run -i ./extract_frames.py --video_name={video_dropdown.value}\n",
    "    %run -i ./demo.py --model_name={model_dropdown.value} --video_name={video_dropdown.value}\n",
    "    video_path = \"./video_output/\" + video_dropdown.value\n",
    "Video(video_path, embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyUzIqvd3rue"
   },
   "source": [
    "## Training of new model\n",
    "\n",
    "This section allows the training/testing of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to generate training and testing lists base on cs json file\n",
    "def training_testing_list():\n",
    "    split_setting = \"CS\"\n",
    "    cs_filepath = \"./Toyota_Smarthome/pipline/data/i3d_CS.json\"\n",
    "    if split_setting == \"CS\":\n",
    "        split_setting_file = open(cs_filepath)\n",
    "        split_setting_json = json.load(split_setting_file)\n",
    "    training_list = []\n",
    "    testing_list = []\n",
    "    for video_key, video_data in split_setting_json.items():\n",
    "        if video_data[\"subset\"] == \"training\":\n",
    "            training_list.append(video_key[:-4] + \".mp4\")\n",
    "        elif video_data[\"subset\"] == \"testing\":\n",
    "            testing_list.append(video_key[:-4] + \".mp4\")\n",
    "    #sort lists according to naming\n",
    "    training_list.sort()\n",
    "    testing_list.sort()\n",
    "    return training_list, testing_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose datasets for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ3NT9Et3wnT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if current_pipeline == \"TSU\":\n",
    "    training_list, testing_list = training_testing_list()\n",
    "elif current_pipeline == \"STEP\":\n",
    "    training_list = os.listdir(os.path.join(\"./datasets/ava/videos/\", \"train_vid\"))\n",
    "    testing_list = os.listdir(os.path.join(\"./datasets/ava/videos/\", \"val_vid\"))\n",
    "\n",
    "\n",
    "training_box = widgets.BoundedIntText(value=1, min=1, max=100)\n",
    "testing_box = widgets.BoundedIntText(value=1, min=1, max=100)\n",
    "\n",
    "tot_train_vid = len(training_list)\n",
    "tot_test_vid = len(testing_list)\n",
    "\n",
    "training_label = widgets.Label(value=\"% of Training video (Total: \" + str(tot_train_vid) + \")\")\n",
    "testing_label = widgets.Label(value=\"% of Training video (Total: \" + str(tot_test_vid) + \")\")\n",
    "\n",
    "display(training_label)\n",
    "display(training_box)\n",
    "display(testing_label)\n",
    "display(testing_box)\n",
    "\n",
    "###new\n",
    "\n",
    "selected_videos = []\n",
    "\n",
    "but = widgets.Button(description = 'Enter')\n",
    "if current_pipeline == \"TSU\":\n",
    "    def on_button_clicked(b):\n",
    "        global selected_videos_string\n",
    "        sel_num_train = int((training_box.value/100) * tot_train_vid)\n",
    "        if sel_num_train < 1:\n",
    "            sel_num_train = 1\n",
    "        sel_num_test = int((testing_box.value/100) * tot_test_vid)\n",
    "        if sel_num_test < 1:\n",
    "            sel_num_test = 1\n",
    "        train_list = training_list[0:sel_num_train]\n",
    "        test_list = testing_list[0:sel_num_test]\n",
    "        combine_dataset = train_list + test_list\n",
    "        selected_videos = list(combine_dataset)\n",
    "        for i in range(len(selected_videos)):\n",
    "            selected_videos[i] = selected_videos[i].replace('.mp4','')\n",
    "        selected_videos_string=(','.join(selected_videos))\n",
    "elif current_pipeline == \"STEP\":\n",
    "    def on_button_clicked(b):\n",
    "        global selected_train_videos\n",
    "        global selected_test_videos\n",
    "        sel_num_train = int((training_box.value/100) * tot_train_vid)\n",
    "        if sel_num_train < 1:\n",
    "            sel_num_train = 1\n",
    "        sel_num_test = int((testing_box.value/100) * tot_test_vid)\n",
    "        if sel_num_test < 1:\n",
    "            sel_num_test = 1\n",
    "        train_list = training_list[0:sel_num_train]\n",
    "        test_list = testing_list[0:sel_num_test]\n",
    "        for i in range(len(train_list)):\n",
    "            train_list[i] = train_list[i].replace('.mp4','')\n",
    "            train_list[i] = train_list[i].replace('.mkv','')\n",
    "            train_list[i] = train_list[i].replace('.webm','')\n",
    "        for i in range(len(test_list)):\n",
    "            test_list[i] = test_list[i].replace('.mp4','')\n",
    "            test_list[i] = test_list[i].replace('.mkv','')\n",
    "            test_list[i] = test_list[i].replace('.webm','')\n",
    "        selected_train_videos=(','.join(train_list))\n",
    "        selected_test_videos=(','.join(test_list))\n",
    "\n",
    "but.on_click(on_button_clicked)\n",
    "\n",
    "display(but)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model name, Batch size, Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp = widgets.Text(description='Model name:')\n",
    "batch_size = widgets.BoundedIntText(description='Batch size:',\n",
    "                                   value=2,\n",
    "                                   max=4)\n",
    "epochs = widgets.BoundedIntText(description='Epochs:',\n",
    "                               value=1000,\n",
    "                               max=1000)\n",
    "learning_rate = widgets.BoundedIntText(value=1)\n",
    "button = widgets.Button(description=\"Enter\")\n",
    "\n",
    "button = widgets.Button(description=\"Enter\")\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    inp.value\n",
    "    batch_size.value\n",
    "    epochs.value\n",
    "    learning_rate.value\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "display(inp)\n",
    "display(batch_size)\n",
    "display(epochs)\n",
    "display(widgets.HBox([widgets.Label(value=\"Learning Rate:\"), learning_rate]))\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global current_pipeline\n",
    "\n",
    "model_name = inp.value\n",
    "epochValue = (epochs.value)\n",
    "batchSize = str(batch_size.value)\n",
    "lrValue = learning_rate.value\n",
    "\n",
    "if current_pipeline == \"TSU\":\n",
    "    %run -i ./Toyota_Smarthome/pipline/train.py -video_train_test={selected_videos_string} -model=PDAN -name={model_name} -batch_size={batchSize} -epoch={epochValue} -lr={lrValue}\n",
    "    %wandb {wandb_username.value}/ICT3104_project\n",
    "elif current_pipeline == \"STEP\":\n",
    "    %run -i ./overwrite_csv_trainval.py --video_train={selected_train_videos} --video_test={selected_test_videos}\n",
    "    %run -i ./scripts/generate_label.py ./datasets/ava/label/new_train.csv\n",
    "    %run -i ./scripts/generate_label.py ./datasets/ava/label/new_val.csv\n",
    "    %run -i ./train.py --model_name={model_name} --batch_size={batchSize} --max_epochs={epochValue} --base_lr={lrValue}\n",
    "    %wandb {wandb_username.value}/ICT3104_project_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4pbFLqFs08xy"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
